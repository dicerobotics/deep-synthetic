## Comments by Arshad MA

## Train and test the CUT Model
Objective: Transferring style from OktalSE simulated images onto MWIR real images and vice versa.

``` bash
cd ./scripts/
./run_real2cut.sh
./run_sim2cut.sh
```

**Output**  
`/workspace/deep-synthetic/results/mwir_real2cut/test_latest/images/ ` 
`/workspace/deep-synthetic/results/mwir_sim2cut/test_latest/images/ ` 

### **Nomenclature**
**Experiments**  
`mwir_real2cut`: Transferring style from OktalSE simulated images onto MWIR real images.  
`mwir_sim2cut`: Transferring style from MWIR real images onto OktalSE simulated images.  

**Images**  
`mwir_real` : Real MWIR Images from the SENSIAC Dataset placed in datasets/real_A for training.  
`mwir_sim`  : Simulated MWIR image generated with OktalSE simulator placed in datasets/real_B for training.  
`mwir_real2cut` : Images produced by CUT by transferring style of mwir_sim onto mwir_real.  
`mwir_sim2cut`  : Images produced by CUT by transferring style of mwir_real onto mwir_sim.  

### **Directory contents**  
**Experiment:** mwir_real2cut   
`datasets/mwir_real2cut/train_A`: mwir_real    
`datasets/mwir_real2cut/train_B`: mwir_sim    
`datasets/mwir_real2cut/test_A`: mwir_real (unscene during training)  
`datasets/mwir_real2cut/test_B`: mwir_sim  (unscene during training)  
`results/mwir_real2cut/test_lastest/images/real_A/`:   
    - Contains the first `n` images from testA/ — these is your actual input to the CUT model (e.g. mwir_real). `n` defaults to 50  
`results/mwir_real2cut/test_lastest/images/fake_B/`:  
    - Contains the generated outputs from those `n` real_A images. `n` defaults to 50  
`results/mwir_real2cut/test_lastest/images/real_B/`:  
    - Contains `n` random images from testB/, not trainB/, and not aligned with real_A. `n` defaults to 50  

| Folder   | Source Directory      | Purpose                                                 |
| -------- | --------------------- | ------------------------------------------------------- |
| `real_A` | `datasets/.../testA/` | Input images to the model (mwir_real)                   |
| `fake_B` | Generated by model    | Style-transferred with CUT                              |
| `real_B` | `datasets/.../testB/` | Random reference images from target domain B (mwir_sim) |


**Experiment:** mwir_sim2cut  
`datasets/mwir_sim2cut/train_A`: mwir_sim  
`datasets/mwir_sim2cut/train_B`: mwir_real  
`datasets/mwir_sim2cut/test_A`: mwir_sim (unscene during training)   
`datasets/mwir_sim2cut/test_B`: mwir_real (unscene during training)  
`results/mwir_sim2cut/test_lastest/images/real_A/`:  
    - Contains the first `n` images from testA/ — this is your actual input to the CUT model (e.g. mwir_sim). `n` defaults to 50  
`results/mwir_sim2cut/test_lastest/images/fake_B/`:  
    - Contains the generated outputs from those `n` real_A images. `n` defaults to 50  
`results/mwir_sim2cut/test_lastest/images/real_B/`:  
    - Contains `n` random images from testB/, not trainB/, and not aligned with real_A. `n` defaults to 50  

| Folder   | Source Directory      | Purpose                                                  |
| -------- | --------------------- | -------------------------------------------------------- |
| `real_A` | `datasets/.../testA/` | Input images to the model (mwir_sim)                     |
| `fake_B` | Generated by model    | Style-transferred with CUT                               |
| `real_B` | `datasets/.../testB/` | Random reference images from target domain B (mwir_real) |


**Important Notes**:   
CUT is designed for unpaired image-to-image translation.  
The real_B/ folder in the results is just for qualitative comparison — it does not correspond to any particular real_A image unless you're using a paired dataset (which CUT doesn't require).  


### **Image similarity metrices with good result ranges**
| Metric                                                | Based On                       | Measures                       | Robust To                              | Best For               | **Typical Range**              | **Good Result**                                                     |
| ----------------------------------------------------- | ------------------------------ | ------------------------------ | -------------------------------------- | ---------------------- | ------------------------------ | ------------------------------------------------------------------- |
| **PSNR** (Peak Signal-to-Noise Ratio)                 | Pixel-wise error (log scale)   | Pixel-level fidelity           | None (sensitive to small shifts/noise) | Compression, denoising | **\[20 – 50] dB**              | **>30 dB** (acceptable), **>40 dB** (high quality)                  |
| **LPIPS** (Learned Perceptual Image Patch Similarity) | Deep network features          | Perceptual/semantic similarity | Misalignment, texture, color shifts    | GANs, synthesis        | **\[0 – 1]** (lower is better) | **<0.3** (good), **<0.2** (very close), **<0.1** (almost identical) |
| **SSIM** (Structural Similarity Index)                | Luminance, contrast, structure | Structural similarity          | Noise, brightness shifts               | General image quality  | **\[0 – 1]**                   | **>0.85** (good), **>0.95** (very good)                             |


**Our Results**  
Experiment: `mwir_real2cut`  
Samples: 50 (Test set)  

| Comparison              | Value     |
| ----------------------- | --------- |
|PSNR (fake_B vs real_B)  | 16.23 dB  |
|LPIPS (fake_B vs real_B) | 0.3723    | 
|SSIM (fake_B vs real_B)  | 0.6455    |  
| SSIM (real_A vs fake_B) | 0.7259    |  

Samples: 9200 (Complete dataset: train set and test set) 

| Comparison              | Value   |
| ----------------------- | -----   |
| PSNR (fake_B vs real_B) | 13.91 dB|  
| LPIPS (fake_B vs real_B)| 0.3865  |
| SSIM (fake_B vs real_B) | 0.5578  |
| SSIM (real_A vs fake_B) | 0.6943  |